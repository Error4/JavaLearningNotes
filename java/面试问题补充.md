面试问题补充

# 1.poi

由于在项目中使用POI导出execl，导致JAVA虚拟机OOM，采用以下方式解决问题：

原先方式：
g_wb = new XSSFWorkbook(sourceFile.getInputStream());

改为：
g_wb = new XSSFWorkbook(sourceFile.getInputStream());
workbook = new SXSSFWorkbook(g_wb);

**XSSFWorkbook** 

其 对应的是EXCEL2007+(1048576行，16384列)扩展名 .xlsx，最多可以 导出 104 万行，不过 这样 就伴随着一个问题---OOM 内存溢出，原因是 你所 创建的 book sheet row cell 等 此时是存在内存的并没有持久化

**SXSSFWorkbook**

因为数据量过大导致内存吃不消无法写文件,利用该API读一批写一批

# 2.**微服务注册中心如何承载大型系统的千万级访问**

首先，各个服务内的Eureka Client组件，默认情况下，每隔30秒会发送一个请求到Eureka Server，来拉取最近有变化的服务信息。除此之外，Eureka还有一个心跳机制，各个Eureka Client每隔30秒会发送一次心跳到Eureka Server。

所以通过**设置一个适当的拉取注册表以及发送心跳的频率，可以保证大规模系统里对Eureka Server的请求压力不会太大。**

Eureka注册表核心源码如下：

```java
public abstract class AbstractInstanceRegistry implements InstanceRegistry{
	private final ConcurrentHashMap<String, Map<String, Lease<InstanceInfo>>> registry = new ConcurrentHashMap();
} 
```

首先，这个ConcurrentHashMap的key就是服务名称，充当value的map则存储了服务的多个实例。维护注册表、拉取注册表、更新心跳时间，全部发生在内存里。

另外，Eureka Server还采用了多级缓存机制来提升响应速度：

- 在拉取注册表的时候：

- - 首先从**ReadOnlyCacheMap**里查缓存的注册表。

- - 若没有，就找**ReadWriteCacheMap**里缓存的注册表。

- - 如果还没有，就从**内存中获取实际的注册表数据。**

- 在注册表发生变更的时候：

- - 会在内存中更新变更的注册表数据，同时**过期掉ReadWriteCacheMap**。

- - 此过程不会影响ReadOnlyCacheMap提供人家查询注册表。

- - 一段时间内（默认30秒），各服务拉取注册表会直接读ReadOnlyCacheMap

- - 30秒过后，Eureka Server的后台线程发现ReadWriteCacheMap已经清空了，也会清空ReadOnlyCacheMap中的缓存

- - 下次有服务拉取注册表，又会从内存中获取最新的数据了，同时填充各个缓存。

综上，**通过纯内存的注册表，保证了所有的请求都可以在内存处理，确保了极高的性能，,多级缓存机制，确保了不会针对内存数据结构发生频繁的读写并发冲突操作，进一步提升性能。**

# 3.**Spring Cloud底层原理概述**

# 4.redis实现分布式锁

从2.6.12版本开始，redis为SET命令增加了一系列选项:

`set [key] NX/XX EX/PX [expiration]`

- EX seconds – 设置键key的过期时间，单位时秒
- PX milliseconds – 设置键key的过期时间，单位时毫秒
- NX – 只有键key不存在的时候才会设置key的值
- XX – 只有键key存在的时候才会设置key的值

set key NX EX 100，即可代表旧版本redis中 setNX+expire命令

# 5.TLAB

在Java中，创建一个对象的方法有很多种，但是无论如何，对象在创建过程中，都需要进行内存分配。

但是，因为堆是全局共享的，因此在同一时间，可能有多个线程在堆上申请空间

为了解决这个并发问题，对象的内存分配过程就必须进行同步控制。但是我们都知道，无论是使用哪种同步方案（实际上虚拟机使用的可能是CAS），都会影响内存的分配效率。

而Java对象的分配是Java中的高频操作，所有，人们想到另外一个办法来提升效率。这里我们重点说一个HotSpot虚拟机的方案：

> 每个线程在Java堆中预先分配一小块内存，然后再给对象分配内存的时候，直接在自己这块”私有”内存中分配，当这部分区域用完之后，再分配新的”私有”内存。

这种方案被称之为TLAB分配，即Thread Local Allocation Buffer。这部分Buffer是从堆中划分出来的，但是是本地线程独享的。

### **什么是TLAB**

TLAB，线程本地分配缓存区，是虚拟机在堆内存的eden划分出来的一块专用空间，是线程专属的。在虚拟机的TLAB功能启动的情况下，在线程初始化时，虚拟机会为每个线程分配一块TLAB空间，只给当前线程使用，这样每个线程都单独拥有一个空间，如果需要分配内存，就在自己的空间上分配，这样就不存在竞争的情况，可以大大提升分配效率。

所以说，因为有了TLAB技术，堆内存并不是完完全全的线程共享，其eden区域中还是有一部分空间是分配给线程独享的。

需要注意，我们说TLAB是线程独享的，但是只是在“分配”这个动作上是线程独享的

TLAB空间的内存非常小，默认情况下仅占有整个Eden空间的1%

### **TLAB带来的问题**

比如一个线程的TLAB空间有100KB，其中已经使用了80KB，当需要再分配一个30KB的对象时，就无法直接在TLAB中分配，遇到这种情况时，有两种处理方案：

1、如果一个对象需要的空间大小超过TLAB中剩余的空间大小，则直接在堆内存中对该对象进行内存分配。

2、如果一个对象需要的空间大小超过TLAB中剩余的空间大小，则废弃当前TLAB，重新申请TLAB空间再次进行内存分配。

以上两个方案各有利弊，如果采用方案1，那么就可能存在着一种极端情况，就是TLAB只剩下1KB，就会导致后续需要分配的大多数对象都需要在堆内存直接分配。

如果采用方案2，也有可能存在频繁废弃TLAB，频繁申请TLAB的情况，而我们知道，虽然在TLAB上分配内存是线程独享的，但是TLAB内存自己从堆中划分出来的过程确实可能存在冲突的，所以，TLAB的分配过程其实也是需要并发控制的。而频繁的TLAB分配就失去了使用TLAB的意义。

为了解决这两个方案存在的问题，虚拟机定义了一个refill_waste的值，这个值可以翻译为“最大浪费空间”。

当请求分配的内存大于refill_waste的时候，会选择在堆内存中分配。若小于refill_waste值，则会废弃当前TLAB，重新创建TLAB进行对象内存分配。

# 6.自动装箱拆箱原理

装箱就是自动将基本数据类型转换为包装器类型；拆箱就是自动将包装器类型转换为基本数据类型。

以下述为例

```java
public class Main {
    public static void main(String[] args) {
    //自动装箱
    Integer total = 99;

    //自定拆箱
    int totalprim = total;
    }
}
```

- 拆箱

  系统为我们执行了： int totalprim = total.intValue();

  ```java
  public int intValue() {
      return value;
    }
  ```

- 装箱

  系统为我们执行了： Integer total = Integer.valueOf(99);

  ```sql
  
    public static Integer valueOf(int i) {
      if(i >= -128 && i <= IntegerCache.high)
        return IntegerCache.cache[i + 128];
      else
        return new Integer(i);
    }
  ```

# 7.泛型擦除

Java 中的**泛型基本上都是在编译器**这个层次来实现的。在**生成的 Java 字节代码中是不包含泛 型中的类型信息**的

在泛型类被类型擦除的时候，如果类型参数部分没有指定上限，如 <T> 会被转译成普通的 `Object` 类型，如果指定了上限，则类型参数被替换成类型上限。

- 类型上限

  extends 关键字指定泛型类型的上界，表示该类型必须是继承某个类，或者实现某个接口，也可以是这个类或接口本身。

  ```java
  public <K extends Number> K test(K e) {
          return e;
      }
  ```

  **注意：对于 ？ extends 的通配符限定泛型，我们无法向里面添加元素(只可以添加null)，只能读取其中的元素。**

- 类型下限

  super 指定泛型类型的下界，表示参数化的类型可能是所指定的类型，或者是此类型的父类型，直至 Object。super 提供了多态支持。

  ```java
  class Fruit {}
  
  class Apple extends Fruit {}
  
  class Banna extends Fruit {}
  
  class FujiApple extends Apple {}
   public static void main(String[] args) {
          List<? super FujiApple> list = new ArrayList<Apple>();
          List<? super FujiApple> list1 = new ArrayList<Fruit>();
          //编译错误
          //List<? super FujiApple> list2 = new ArrayList<Banana>();
          test(list);
          test(list1);
      }
  ```

  **注意：对于 ？super 的通配符限定泛型，我们可以读取其中的元素，但读取出来的元素会变为 Object 类型。**

  注意：？叫做通配符，表示任意类型，上述已经出现。它与类型参数T的不同点如下：

  - T 只有extends一种限定方式，<T extends List>是合法的，<T super List>是不合法的
  - ？有extends与super两种限定方式，即<? extends List> 与<? super List>都是合法的
  - T 用于泛型类和泛型方法的定义。？用于泛型方法的调用和形参

在Java中，可以利用反射获取返回值泛型和参数的泛型，因为**class字节码中会有个signature字段来保存泛型信息**

```java
//获取参数类型
Type[] parameterTypes = declaredMethod.getGenericParameterTypes();

//获取返回值的类型，此处不是数组，请注意，返回值只能是一个
Type genericReturnType = declaredMethod.getGenericReturnType();
```

## 继承泛型类型的多态麻烦

以下面的类为例

```java
class SonPair extends Pair<String>{  
          public void setFirst(String fir){....}  
}
```

很明显，程序员的本意是想在SonPair类中覆盖父类Pair的setFirst(T fir)这个方法。但事实上，Pair在编译阶段已经被类型擦除为Pair了，它的setFirst方法变成了setFirst(Object fir)。 那么SonPair中setFirst(String)当然无法覆盖住父类的setFirst(Object)了。

而编译器**会自动在 SonPair中生成一个桥方法(bridge method ) ：**

```java
public void setFirst(Object fir)
{
    setFirst((String) fir)
} 
```

**假设 我们还想在 SonPair 中覆盖getFirst()方法呢？**

```java
class SonPair extends Pair<String>
{
      public String getFirst(){....}  
}  
```

- 由于需要桥方法来覆盖父类中的getFirst，编译器会自动在SonPair中生成一个 public Object getFirst()桥方法。 **（干货——引入了桥方法，该方法是编译器生成的，不是程序员码出来的）**
- **但是，疑问来了，SonPair中出现了两个方法签名一样的方法(只是返回类型不同)：**
  - **String getFirst() // 自己定义的方法**
  - **Object getFirst() // 编译器生成的桥方法**

此时，**出现方法签名相同的多个方法存在于一个类中**，如果在编译阶段肯定无法通过，但**JVM会用参数类型和返回类型来确定一个方法**

# 8.Spring 中，@Autowired 和@Resource 

## 区别：

@Resource 是 JSR-250 标准的注释，不属于 Spring 中的标准注解，而@Autowired 属于 Spring 中的注解。

@Autowired 默认按类型装配（byType），如果要按名称装配的话，必须和@Qualifier 注解一起使用。

```java
@Autowired() 
@Qualifier("myBean")
private MyBean myBean;
```

@Resource，默认按名称进行装配（byName），通过 name 属性设置名称，如果没有设置 name 属性，则默认取字段名名称进行查找。如果还是找不到名称，则会按照类型进行装配。需要注意的是，如果 name 属性被设置了，那么必须是按照名称进行装配。

```java
@Resource("myBean")
private MyBean myBean;
```

## 实现原理：

- @Autowired是通过BeanPostProcessor接口的实现类AutowiredAnnotationBeanPostProcessor来实现对bean对象对其他bean对象的依赖注入的；

- @Resource和是通过BeanPostProcessor接口的实现类CommonAnnotationBeanPostProcessor来实现的

# 9.Java  IO中的设计模式

 定义:

Decorator装饰器，就是**动态地给一个对象添加一些额外的职责**，动态扩展，和下面继承（静态扩展）的比较。因此，装饰器模式具有如下的特征：

1. 它必须持有一个被装饰的对象（作为成员变量）。
2. 它必须拥有与被装饰对象相同的接口（多态调用、扩展需要）。
3. 它可以给被装饰对象添加额外的功能。

总结：保持接口，动态增强性能。

装饰器通过包装一个装饰对象来扩展其功能，而又不改变其接口，这实际上是基于对象的适配器模式的一种变种。与对象的适配器模式异同：

1. 相同点：都拥有一个目标对象。
2. 不同点：**适配器模式需要实现旧接口，而装饰器模式必须实现相同接口。**

**适配器模式是在适配器中，重写旧接口的方法来调用新接口方法，来实现旧接口不改变，同时使用新接口的目的。新接口适配旧接口。**

**而装饰模式，是装饰器和旧接口实现相同的接口，在调用新接口的方法中，会调用旧接口的方法，并对其进行扩展。**

例子：

`InputStreamReader` 是字节流与字符流之间的桥梁，它的实现使用了适配器模式。

`InputStreamReader` 的构造器需要传入一个字节流 `InputSream`，以及可选的字符集。如果没有传入字符集就会使用默认的。通过持有一个 `InputStream`，`InputStreamReader` 拥有了该接口的功能。同时，`InputStreamReader` 还是一个实现了 `Reader` 类，这样一来它就把 `InputStream` 适配成了一个 `Reader` 类。

`BufferedInputStream`“装饰”了InputStream的内部工作方式，使得流的读入操作使用了缓冲机制

# 10.静态代理和动态代理

### 静态代理：

静态代理在使用时,需要定义接口或者父类,被代理对象与代理对象一起实现相同的接口或者是继承相同父类.

模拟保存动作,定义一个保存动作的接口:IUserDao.java,然后目标对象实现这个接口的方法UserDao.java,此时如果使用静态代理方式,就需要在代理对象(UserDaoProxy.java)中也实现IUserDao接口.调用的时候通过调用代理对象的方法来调用目标对象，**代理对象与目标对象要实现相同的接口,然后通过调用相同的方法来调用目标对象的方法**

### 动态代理：

因为代理对象需要与目标对象实现一样的接口,所以会有很多代理类,类太多.同时,一旦接口增加方法,目标对象与代理对象都要维护，所以需要动态代理

**动态代理有以下特点:**
1.代理对象,不需要实现接口
2.代理对象的生成,是利用JDK的API,动态的在内存中构建代理对象(需要我们指定创建代理对象/目标对象实现的接口的类型)

# 11.Redis hot key&big key问题

hot key：有几十万的请求去访问redis上的某个特定key。那么，这样会造成流量过于集中，达到物理网卡上限，从而导致这台redis的服务器宕机，进而导致数据库服务不可用。

big key：数据量大的 key ，由于其数据大小远大于其他key，导致经过分片之后，某个具体存储这个 big key 的实例内存使用量远大于其他实例，造成，内存不足，拖累整个集群的使用，比如大V的粉丝列表

### 如何发现hot key

#### *方法一:凭借业务经验，进行预估哪些是热key*

缺点，并非所有业务都能预估出哪些key是热key。

#### *方法二:在客户端进行收集*

操作redis之前，加入一行代码进行数据统计，缺点就是对客户端代码造成入侵。

#### *方法三用redis自带命令*

(1)monitor命令，该命令可以实时抓取出redis服务器接收到的命令，然后写代码统计出热key是啥。当然，也有现成的分析工具可以给你使用，比如`redis-faina`。但是该命令在高并发的条件下，有内存增暴增的隐患，还会降低redis的性能。
(2)hotkeys参数，redis 4.0.3提供了redis-cli的热点key发现功能，执行redis-cli时加上–hotkeys选项即可。但是该参数在执行的时候，如果key比较多，执行起来比较慢。

### 如何解决hot key

#### *(1)利用二级缓存*

比如利用`ehcache`，或者一个`HashMap`都可以。在你发现热key以后，把热key加载到系统的JVM中。
针对这种热key请求，会直接从jvm中取，而不会走到redis层。

#### *(2)利用分片算法的特性，对key进行打散处理*

这个方案也很简单。不要让key走到同一台redis上不就行了。我们把这个key，在多个redis上都存一份不就好了。接下来，有热key请求进来的时候，我们就在有备份的redis上随机选取一台，进行访问取值，返回数据。

### 如何发现big key

redis-cli自带--bigkeys，例如：redis-cli -h -a --bigkeys，但是只能得到某种类型的最大的一个key

### 如何解决big key

对 big key 进行拆分

# 12.逃逸分析

逃逸分析的基本行为就是分析对象动态作用域，当一个对象在方法中定义后，可能被外部方法所引用，成为方法逃逸；甚至可能被外部线程访问，称为线程逃逸。

如果能证明变量不会逃逸到方法和线程之外，JVM则能对这个变量进行一些优化，如下所示：

- 栈上分配

  一般情况，对象都是在java堆分配的，但如果能确定变量不会逃逸出方法，那么再栈上分配也是个优化方案，**对象所占用的内存空间就会随栈帧出栈而销毁。**

- 同步消除

  线程同步本身相对耗时，如果能确定一个变量不会逃逸出线程，就可以同步消除
  
  **锁消除是指对于被检测出不可能存在竞争的共享数据的锁进行消除。**
  **锁消除主要是通过逃逸分析来支持**

# 13.Hash冲突

- 开放定址

  其基本思想是：当关键字key的哈希地址p=H（key）出现冲突时，以p为基础，产生另一个哈希地址p1，如果p1仍然冲突，再以p为基础，产生另一个哈希地址p2

  **线性探测再散列**

  dii=1，2，3，…，m-1

  这种方法的特点是：冲突发生时，顺序查看表中下一单元，直到找出一个空单元或查遍全表。

- 再哈希

  同时构造多个不同的哈希函数：

  Hi=RH1（key）  i=1，2，…，k

  当哈希地址Hi=RH1（key）发生冲突时，再计算Hi=RH2（key）

- 链地址法

  所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第i个单元中，比如Java中HashMap

# 14.java代理

CGLIB其原理也很简单，对指定的目标类生成一个子类，并覆盖其中方法实现增强，但**由于采用的是继承，所以不能对final修饰的类进行代理。**

# 15.enum 与 Enum 

**enum是一个关键字，使用enum定义的枚举类本质上就相对于一个类继承了Enum这个抽象类而已**

# 16.单机环境下利用事件驱动进行代码解耦

Guava 中的 EventBus 的使用。EventBus 处理的事情类似观察者模式，基于事件驱动，观察者们监听自己感兴趣的特定事件，进行相应的处理。将发生事件的代码和事件处理的代码进行了解耦。

# 17.full gc的条件

- 直接调用System.gc（）

- 老年代满

- 持久代满

- 统计得到的Minor GC晋升到旧生代的平均大小大于旧生代的剩余空间（Hotspot虚拟机）

  例如程序第一次触发MinorGC后，有6MB的对象晋升到旧生代，那么当下一次Minor GC发生时，首先检查旧生代的剩余空间是否大于6MB，如果小于6MB，则执行Full GC。

  


# 18.String不可变

主要是为了“效率” 和 “安全性” 的缘故。若 String允许被继承, 由于它的高度被使用率, 可能会降低程序的性能，所以String被定义成final。

比如就是在并发场景下，多个线程同时读一个资源，是不会引发竟态条件的。只有对资源做写操作才有危险。不可变对象不能被写，所以**线程安全**

String还有一个**字符串常量池**的使用，这样在大量使用字符串的情况下，可以节省内存空间，提高效率。但之所以能实现这个特性，String的不可变性是最基本的一个必要条件

# 19.mysql count（1），count(*)

`COUNT(常量)` 和 `COUNT(*)` 表示的是直接查询符合条件的数据库表的行数。

而`COUNT(列名)`表示的是查询符合条件的列的值不为NULL的行数。

对于`count(1)`和`count(*)`，MySQL（5.5之后，大概）的优化是完全一样的，根本不存在谁更快！

MyISAM在统计表的总行数的时候会很快，但是有个大前提，**不能加有任何WHERE条件**。这是因为：MyISAM对于表的行数做了优化，具体做法是有一个变量存储了表的行数，如果查询条件没有WHERE条件则是查询表中一共有多少条数据，MyISAM可以做到迅速返回

# 20 一致性Hash的一致性如何理解

比如我们有三台服务器，那么需要缓存的数据可以通过简单的膜3取余，来决定缓存到哪一个服务器上。

这样会有个问题，也就是当服务器数量变化的时候（比如现有服务器太少，需要新加），我们需要改变上述映射规则（否则没有数据缓存到新的服务器上），也就是全量数据都需要重新映射到对应的服务器上。这就是不一致。

所以一致性哈希的一致性体现在，**当服务器数量变化时，影响到的，数据—服务器，对应关系变化不是全量的。（对于绝大多数数据来说，是前后一致的）**

# 21.Java中用到的设计模式

## IO 装饰者模式

以 InputStream 为例，
InputStream 是抽象组件； 

FileInputStream 是 InputStream 的子类，属于具体组件，提供了字节流的输入操作； 

FilterInputStream 属于抽象装饰者，装饰者用于装饰组件，为组件提供额外的功能。例如 BufferedInputStream 为 FileInputStream 提供缓存的功能。

## AQS 模板模式

# 22.Java1.8后，HashMap为什么在链表长度为8的时候转化为红黑树

## 为什么不直接使用红黑树，而是要先使用链表实在不行再转红黑树呢？

因为**树节点的大小是链表节点大小的两倍**，所以只有在容器中包含足够的节点保证使用才用它”

## 为什么是8，而不是9不是10？

为了配合使用分布良好的hashCode，树节点很少使用。并且在理想状态下，受随机分布的hashCode影响，链表中的节点遵循泊松分布，而且根据统计，链表中节点数是8的概率已经接近千分之一，而且此时链表的性能已经很差了。所以在这种比较罕见和极端的情况下，才会把链表转变为红黑树。

# 23.volatile，内存重排序到底怎么避免的？

Volatile 变量具有 synchronized 的可见性特性，但是不具备原子特性。
 一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。

在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果；但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。这是就需要内存屏障来保证可见性了。

内存屏障分为两种：Load Barrier 和 Store Barrier即读屏障和写屏障。

- 对于Load Barrier来说，在指令前插入Load Barrier，可以让高速缓存中的数据失效，强制从新从主内存加载数据；
- 对于Store Barrier来说，在指令后插入Store Barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见。

volatile的内存屏障策略非常严格保守，非常悲观且毫无安全感的心态：

- 在每个volatile写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障；
- 在每个volatile读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障；

由于内存屏障的作用，避免了volatile变量和其它指令重排序、线程之间实现了通信，使得volatile表现出了锁的特性。